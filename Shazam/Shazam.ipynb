{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YrZAgqpKL6z",
        "outputId": "e4522b38-010c-443d-8eff-70c9982fc979"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/337.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m337.3/337.3 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h--2025-08-25 07:37:43--  https://os.unil.cloud.switch.ch/fma/fma_small.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.16, 2001:620:5ca1:201::214\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7679594875 (7.2G) [application/zip]\n",
            "Saving to: â€˜fma_small.zipâ€™\n",
            "\n",
            "fma_small.zip       100%[===================>]   7.15G  23.0MB/s    in 5m 51s  \n",
            "\n",
            "2025-08-25 07:43:35 (20.9 MB/s) - â€˜fma_small.zipâ€™ saved [7679594875/7679594875]\n",
            "\n",
            "--2025-08-25 07:43:35--  https://os.unil.cloud.switch.ch/fma/fma_metadata.zip\n",
            "Resolving os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)... 86.119.28.16, 2001:620:5ca1:201::214\n",
            "Connecting to os.unil.cloud.switch.ch (os.unil.cloud.switch.ch)|86.119.28.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 358412441 (342M) [application/zip]\n",
            "Saving to: â€˜fma_metadata.zipâ€™\n",
            "\n",
            "fma_metadata.zip    100%[===================>] 341.81M  22.3MB/s    in 17s     \n",
            "\n",
            "2025-08-25 07:43:54 (19.7 MB/s) - â€˜fma_metadata.zipâ€™ saved [358412441/358412441]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "!pip install torchaudio qdrant-client --quiet\n",
        "\n",
        "# Download metadata and audio\n",
        "!wget -nc https://os.unil.cloud.switch.ch/fma/fma_small.zip -O fma_small.zip\n",
        "!wget -nc https://os.unil.cloud.switch.ch/fma/fma_metadata.zip -O fma_metadata.zip\n",
        "\n",
        "# Unzip (audio: fma_small, metadata: CSVs)\n",
        "!unzip -q -n fma_small.zip -d ./fma_small\n",
        "!unzip -q -n fma_metadata.zip -d ./fma_metadata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tracks = pd.read_csv(\"fma_metadata/fma_metadata/tracks.csv\", index_col=0, header=[0,1])\n",
        "genres = pd.read_csv(\"fma_metadata/fma_metadata/genres.csv\", index_col=0)\n",
        "\n",
        "# Filter only small set\n",
        "subset = tracks['set', 'subset'] == 'small'\n",
        "small_tracks = tracks[subset]\n",
        "\n",
        "print(\"Total FMA-Small tracks:\", len(small_tracks))\n",
        "small_tracks.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 631
        },
        "id": "t9cPElVpKbUU",
        "outputId": "93b19d8f-1a20-4a9f-ca8e-41d96951f55d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total FMA-Small tracks: 8000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            album                                                     \\\n",
              "         comments         date_created        date_released engineer   \n",
              "track_id                                                               \n",
              "2               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
              "5               0  2008-11-26 01:44:45  2009-01-05 00:00:00      NaN   \n",
              "10              0  2008-11-26 01:45:08  2008-02-06 00:00:00      NaN   \n",
              "140             1  2008-11-26 01:49:59  2007-05-22 00:00:00      NaN   \n",
              "141             0  2008-11-26 01:49:57  2009-01-16 00:00:00      NaN   \n",
              "\n",
              "                                                                           \\\n",
              "         favorites  id                                        information   \n",
              "track_id                                                                    \n",
              "2                4   1                                            <p></p>   \n",
              "5                4   1                                            <p></p>   \n",
              "10               4   6                                                NaN   \n",
              "140              1  61  <p>Alec K. Redfearn &amp; The Eyesores: Ellen ...   \n",
              "141              1  60  <p>A full ensamble of strings, drums, electron...   \n",
              "\n",
              "                                                       ...       track  \\\n",
              "         listens                        producer tags  ... information   \n",
              "track_id                                               ...               \n",
              "2           6073                             NaN   []  ...         NaN   \n",
              "5           6073                             NaN   []  ...         NaN   \n",
              "10         47632                             NaN   []  ...         NaN   \n",
              "140         1300  Alec K. Refearn, Rob Pemberton   []  ...         NaN   \n",
              "141         1304                             NaN   []  ...         NaN   \n",
              "\n",
              "                                 \\\n",
              "         interest language_code   \n",
              "track_id                          \n",
              "2            4656            en   \n",
              "5            1933            en   \n",
              "10          54881            en   \n",
              "140          1593            en   \n",
              "141           839            en   \n",
              "\n",
              "                                                                              \\\n",
              "                                                    license listens lyricist   \n",
              "track_id                                                                       \n",
              "2         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1293      NaN   \n",
              "5         Attribution-NonCommercial-ShareAlike 3.0 Inter...    1151      NaN   \n",
              "10        Attribution-NonCommercial-NoDerivatives (aka M...   50135      NaN   \n",
              "140       Attribution-Noncommercial-No Derivative Works ...    1299      NaN   \n",
              "141       Attribution-Noncommercial-No Derivative Works ...     725      NaN   \n",
              "\n",
              "                                                    \n",
              "         number publisher tags               title  \n",
              "track_id                                            \n",
              "2             3       NaN   []                Food  \n",
              "5             6       NaN   []          This World  \n",
              "10            1       NaN   []             Freeway  \n",
              "140           2       NaN   []  Queen Of The Wires  \n",
              "141           4       NaN   []                Ohio  \n",
              "\n",
              "[5 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-89f7b391-411b-4cf5-ab79-97309b975f64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"10\" halign=\"left\">album</th>\n",
              "      <th>...</th>\n",
              "      <th colspan=\"10\" halign=\"left\">track</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>comments</th>\n",
              "      <th>date_created</th>\n",
              "      <th>date_released</th>\n",
              "      <th>engineer</th>\n",
              "      <th>favorites</th>\n",
              "      <th>id</th>\n",
              "      <th>information</th>\n",
              "      <th>listens</th>\n",
              "      <th>producer</th>\n",
              "      <th>tags</th>\n",
              "      <th>...</th>\n",
              "      <th>information</th>\n",
              "      <th>interest</th>\n",
              "      <th>language_code</th>\n",
              "      <th>license</th>\n",
              "      <th>listens</th>\n",
              "      <th>lyricist</th>\n",
              "      <th>number</th>\n",
              "      <th>publisher</th>\n",
              "      <th>tags</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>track_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4656</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1293</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:44:45</td>\n",
              "      <td>2009-01-05 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>&lt;p&gt;&lt;/p&gt;</td>\n",
              "      <td>6073</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1933</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-ShareAlike 3.0 Inter...</td>\n",
              "      <td>1151</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>This World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:45:08</td>\n",
              "      <td>2008-02-06 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>47632</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54881</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-NonCommercial-NoDerivatives (aka M...</td>\n",
              "      <td>50135</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Freeway</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>1</td>\n",
              "      <td>2008-11-26 01:49:59</td>\n",
              "      <td>2007-05-22 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>61</td>\n",
              "      <td>&lt;p&gt;Alec K. Redfearn &amp;amp; The Eyesores: Ellen ...</td>\n",
              "      <td>1300</td>\n",
              "      <td>Alec K. Refearn, Rob Pemberton</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1593</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-Noncommercial-No Derivative Works ...</td>\n",
              "      <td>1299</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Queen Of The Wires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>0</td>\n",
              "      <td>2008-11-26 01:49:57</td>\n",
              "      <td>2009-01-16 00:00:00</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>60</td>\n",
              "      <td>&lt;p&gt;A full ensamble of strings, drums, electron...</td>\n",
              "      <td>1304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>839</td>\n",
              "      <td>en</td>\n",
              "      <td>Attribution-Noncommercial-No Derivative Works ...</td>\n",
              "      <td>725</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[]</td>\n",
              "      <td>Ohio</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 52 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89f7b391-411b-4cf5-ab79-97309b975f64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-89f7b391-411b-4cf5-ab79-97309b975f64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-89f7b391-411b-4cf5-ab79-97309b975f64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-68f69961-1c8e-4738-8675-bd80adf80e60\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68f69961-1c8e-4738-8675-bd80adf80e60')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-68f69961-1c8e-4738-8675-bd80adf80e60 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "small_tracks"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from tqdm import tqdm\n",
        "\n",
        "DATASET_PATH = \"fma_small/fma_small\"\n",
        "CACHE_PATH = \"/content/fma_cache\"\n",
        "os.makedirs(CACHE_PATH, exist_ok=True)\n",
        "\n",
        "# Parameters\n",
        "clip_duration = 3       # seconds\n",
        "sample_rate = 16000\n",
        "n_mels = 64\n",
        "n_samples = clip_duration * sample_rate\n",
        "\n",
        "# Mel transform\n",
        "mel_transform = torchaudio.transforms.MelSpectrogram(\n",
        "    sample_rate=sample_rate,\n",
        "    n_fft=1024,\n",
        "    hop_length=512,\n",
        "    n_mels=n_mels\n",
        ")\n",
        "\n",
        "# Gather all song paths\n",
        "song_files = [p for p in glob.glob(os.path.join(DATASET_PATH, \"*/*.mp3\"))]\n",
        "song_dirs = {f\"song_{i:06d}\": p for i, p in enumerate(song_files)}\n",
        "\n",
        "# Precompute\n",
        "for song_id, path in tqdm(song_dirs.items(), desc=\"Caching spectrograms\"):\n",
        "    cache_file = os.path.join(CACHE_PATH, f\"{song_id}.pt\")\n",
        "    if os.path.exists(cache_file):\n",
        "        continue  # skip if already cached\n",
        "\n",
        "    try:\n",
        "        waveform, sr = torchaudio.load(path)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {song_id}: {e}\")\n",
        "        continue  # skip problematic file\n",
        "    if waveform.size(1) < 1000:\n",
        "      print(f\"Skipping too short file: {song_id}\")\n",
        "      continue\n",
        "    if sr != sample_rate:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, sample_rate)\n",
        "    if waveform.size(0) > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)  # mono\n",
        "\n",
        "    # Take first clip_duration seconds (or pad if short)\n",
        "    if waveform.size(1) < n_samples:\n",
        "        pad = n_samples - waveform.size(1)\n",
        "        waveform = torch.nn.functional.pad(waveform, (0, pad))\n",
        "    else:\n",
        "        waveform = waveform[:, :n_samples]\n",
        "\n",
        "    mel = mel_transform(waveform)\n",
        "    log_mel = torch.log1p(mel)\n",
        "    log_mel = (log_mel - log_mel.mean()) / (log_mel.std() + 1e-6)\n",
        "    log_mel = log_mel.contiguous()\n",
        "\n",
        "    torch.save(log_mel, cache_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJYDOrqRZKQA",
        "outputId": "1f649a36-c586-4e95-cb84-4ac676e7e53a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Caching spectrograms:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 4986/8000 [00:00<00:00, 43504.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping song_004984: Failed to open the input \"fma_small/fma_small/099/099134.mp3\" (Invalid argument).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Caching spectrograms:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 5815/8000 [01:14<01:38, 22.18it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping song_005817: Failed to open the input \"fma_small/fma_small/108/108925.mp3\" (Invalid argument).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Caching spectrograms:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 7464/8000 [03:41<00:41, 12.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skipping song_007461: Failed to open the input \"fma_small/fma_small/133/133297.mp3\" (Invalid argument).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Caching spectrograms: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8000/8000 [04:29<00:00, 29.72it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torchaudio\n",
        "import random\n",
        "import os\n",
        "\n",
        "class SongTripletDatasetCached(Dataset):\n",
        "    def __init__(self, cache_dir):\n",
        "        self.cache_files = [os.path.join(cache_dir, f) for f in os.listdir(cache_dir)]\n",
        "        self.song_ids = [os.path.basename(f).split(\".pt\")[0] for f in self.cache_files]\n",
        "\n",
        "    def __len__(self):\n",
        "        return 50000  # arbitrary for triplet sampling\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # --- Anchor ---\n",
        "        anchor_id = random.choice(self.song_ids)\n",
        "        anchor = torch.load(os.path.join(CACHE_PATH, f\"{anchor_id}.pt\"))\n",
        "\n",
        "        # --- Positive (same song, different clip) ---\n",
        "        # For simplicity, reuse same clip; could extend to multiple clips\n",
        "        positive = torch.load(os.path.join(CACHE_PATH, f\"{anchor_id}.pt\"))\n",
        "\n",
        "        # --- Negative (different song) ---\n",
        "        neg_id = random.choice([s for s in self.song_ids if s != anchor_id])\n",
        "        negative = torch.load(os.path.join(CACHE_PATH, f\"{neg_id}.pt\"))\n",
        "\n",
        "        return anchor, positive, negative\n"
      ],
      "metadata": {
        "id": "n_e-0luDRapm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "import os\n",
        "\n",
        "# ----------------------------\n",
        "# Embedding Network\n",
        "# ----------------------------\n",
        "class AudioEmbeddingNet(nn.Module):\n",
        "    def __init__(self, embedding_dim=128):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1), nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1, 1))\n",
        "        )\n",
        "        self.fc = nn.Linear(128, embedding_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 1, n_mels, time)\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        return F.normalize(x, p=2, dim=1)  # L2-normalized embeddings\n",
        "\n",
        "# Triplet wrapper\n",
        "class TripletNetwork(nn.Module):\n",
        "    def __init__(self, embedding_net):\n",
        "        super().__init__()\n",
        "        self.embedding_net = embedding_net\n",
        "\n",
        "    def forward(self, anchor, positive, negative):\n",
        "        return (self.embedding_net(anchor),\n",
        "                self.embedding_net(positive),\n",
        "                self.embedding_net(negative))\n"
      ],
      "metadata": {
        "id": "6hpt1UKwLO96"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# ðŸ”¹ 1. Train/Val split\n",
        "def create_loaders(dataset, batch_size=32, val_split=0.2):\n",
        "    val_size = int(len(dataset) * val_split)\n",
        "    train_size = len(dataset) - val_size\n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "# ðŸ”¹ 2. Training loop with early stopping + scheduler\n",
        "def train_model(model, train_loader, val_loader, n_epochs=50, patience=5, save_path=\"best_model.pt\"):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model = model.to(device)\n",
        "\n",
        "    criterion = nn.TripletMarginLoss(margin=1.0, p=2)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode=\"min\", factor=0.5, patience=2)\n",
        "\n",
        "    best_val_loss = np.inf\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        # --- Training ---\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        for anchor, positive, negative in train_loader:\n",
        "            anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
        "            loss = criterion(anchor_out, positive_out, negative_out)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "\n",
        "        # --- Validation ---\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for anchor, positive, negative in val_loader:\n",
        "                anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
        "                anchor_out, positive_out, negative_out = model(anchor, positive, negative)\n",
        "                val_loss = criterion(anchor_out, positive_out, negative_out)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "        avg_val_loss = total_val_loss / len(val_loader)\n",
        "\n",
        "        # ðŸ”¹ Scheduler step\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch:03d} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
        "\n",
        "        # --- Check early stopping ---\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), save_path)  # save best model\n",
        "            print(f\"  âœ… New best model saved (val_loss={best_val_loss:.4f})\")\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            print(f\"  âš ï¸ No improvement (patience {patience_counter}/{patience})\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"â¹ï¸ Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Load best model before returning\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    print(\"ðŸ”„ Best model reloaded from checkpoint\")\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "YGLltewwOcwb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "dataset = SongTripletDatasetCached(CACHE_PATH)\n",
        "val_split = 0.1\n",
        "val_size = int(len(dataset) * val_split)\n",
        "train_size = len(dataset) - val_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Model\n",
        "model = TripletNetwork(AudioEmbeddingNet(embedding_dim=128))\n",
        "\n",
        "# Train\n",
        "best_model = train_model(model, train_loader, val_loader, n_epochs=20, patience=5, save_path=\"triplet_best.pt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heQFrOHSO2hg",
        "outputId": "2e354cb8-1421-4b43-de55-d4e65c9ba230"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 001 | Train Loss: 0.0111 | Val Loss: 0.0035 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0035)\n",
            "Epoch 002 | Train Loss: 0.0031 | Val Loss: 0.0025 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0025)\n",
            "Epoch 003 | Train Loss: 0.0020 | Val Loss: 0.0015 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0015)\n",
            "Epoch 004 | Train Loss: 0.0017 | Val Loss: 0.0025 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 1/5)\n",
            "Epoch 005 | Train Loss: 0.0013 | Val Loss: 0.0019 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 2/5)\n",
            "Epoch 006 | Train Loss: 0.0010 | Val Loss: 0.0013 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0013)\n",
            "Epoch 007 | Train Loss: 0.0009 | Val Loss: 0.0006 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0006)\n",
            "Epoch 008 | Train Loss: 0.0008 | Val Loss: 0.0009 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 1/5)\n",
            "Epoch 009 | Train Loss: 0.0008 | Val Loss: 0.0011 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 2/5)\n",
            "Epoch 010 | Train Loss: 0.0006 | Val Loss: 0.0005 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0005)\n",
            "Epoch 011 | Train Loss: 0.0006 | Val Loss: 0.0011 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 1/5)\n",
            "Epoch 012 | Train Loss: 0.0005 | Val Loss: 0.0004 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0004)\n",
            "Epoch 013 | Train Loss: 0.0006 | Val Loss: 0.0004 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0004)\n",
            "Epoch 014 | Train Loss: 0.0004 | Val Loss: 0.0004 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 1/5)\n",
            "Epoch 015 | Train Loss: 0.0004 | Val Loss: 0.0005 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 2/5)\n",
            "Epoch 016 | Train Loss: 0.0004 | Val Loss: 0.0003 | LR: 0.001000\n",
            "  âœ… New best model saved (val_loss=0.0003)\n",
            "Epoch 017 | Train Loss: 0.0004 | Val Loss: 0.0003 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 1/5)\n",
            "Epoch 018 | Train Loss: 0.0004 | Val Loss: 0.0004 | LR: 0.001000\n",
            "  âš ï¸ No improvement (patience 2/5)\n",
            "Epoch 019 | Train Loss: 0.0003 | Val Loss: 0.0004 | LR: 0.000500\n",
            "  âš ï¸ No improvement (patience 3/5)\n",
            "Epoch 020 | Train Loss: 0.0002 | Val Loss: 0.0003 | LR: 0.000500\n",
            "  âš ï¸ No improvement (patience 4/5)\n",
            "ðŸ”„ Best model reloaded from checkpoint\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "\n",
        "# Parameters\n",
        "SAMPLE_RATE = 22050\n",
        "N_MELS = 128\n",
        "CLIP_DURATION = 30  # seconds\n",
        "N_SAMPLES = SAMPLE_RATE * CLIP_DURATION\n",
        "\n",
        "# Transforms\n",
        "mel_transform = T.MelSpectrogram(\n",
        "    sample_rate=SAMPLE_RATE,\n",
        "    n_fft=1024,\n",
        "    hop_length=512,\n",
        "    n_mels=N_MELS\n",
        ")\n",
        "db_transform = T.AmplitudeToDB()\n",
        "\n",
        "def preprocess_audio(path, device=\"cpu\"):\n",
        "    # Load audio\n",
        "    waveform, sr = torchaudio.load(path)\n",
        "\n",
        "    # Convert to mono\n",
        "    if waveform.size(0) > 1:\n",
        "        waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "    # Resample if needed\n",
        "    if sr != SAMPLE_RATE:\n",
        "        waveform = torchaudio.functional.resample(waveform, sr, SAMPLE_RATE)\n",
        "\n",
        "    # Clip or pad\n",
        "    if waveform.size(1) < N_SAMPLES:\n",
        "        waveform = torch.nn.functional.pad(waveform, (0, N_SAMPLES - waveform.size(1)))\n",
        "    else:\n",
        "        waveform = waveform[:, :N_SAMPLES]\n",
        "\n",
        "    # Mel-spectrogram\n",
        "    mel_spec = mel_transform(waveform)\n",
        "    log_mel_spec = db_transform(mel_spec)\n",
        "\n",
        "    # Normalize\n",
        "    log_mel_spec = (log_mel_spec - log_mel_spec.mean()) / (log_mel_spec.std() + 1e-6)\n",
        "\n",
        "    return log_mel_spec.unsqueeze(0).to(device).contiguous()  # (1, 1, n_mels, time)\n",
        "\n",
        "def embed_song(embedding_net, path, device=\"cpu\"):\n",
        "    embedding_net.eval()\n",
        "    with torch.no_grad():\n",
        "        spec = preprocess_audio(path, device)\n",
        "        emb = embedding_net(spec)  # (1, embedding_dim)\n",
        "        return emb.squeeze(0).cpu().numpy().astype(np.float32)\n"
      ],
      "metadata": {
        "id": "NpypkuiTNLFe"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from qdrant_client import QdrantClient\n",
        "\n",
        "# Connect to Qdrant\n",
        "client = QdrantClient(\":memory:\")\n",
        "\n",
        "# Delete collection\n",
        "client.delete_collection(collection_name=\"songs\")\n",
        "\n",
        "print(\"âœ… Collection 'songs' deleted\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zywICYxpMuY",
        "outputId": "a7c2b982-5be7-41eb-abca-9ba27a68c6ac"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Collection 'songs' deleted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http import models as rest\n",
        "\n",
        "# Qdrant client (local or cloud)\n",
        "#client = QdrantClient(host=\"localhost\", port=6333)\n",
        "client = QdrantClient(\":memory:\")  # only works in current runtime, no network needed\n",
        "\n",
        "# Pick first 500 MP3s from FMA-Small\n",
        "dataset_path = \"fma_small/fma_small\"\n",
        "song_files = sorted(glob.glob(os.path.join(dataset_path, \"*/*.mp3\")))[:1000]\n",
        "\n",
        "# Create or reset collection\n",
        "client.recreate_collection(\n",
        "    collection_name=\"songs\",\n",
        "    vectors_config=rest.VectorParams(size=128, distance=\"Cosine\")\n",
        ")\n",
        "\n",
        "embedding_net = AudioEmbeddingNet(embedding_dim=128)\n",
        "# Load weights from TripletNetwork\n",
        "state_dict = torch.load(\"triplet_best.pt\", map_location=\"cpu\")\n",
        "# If keys are prefixed with 'embedding_net.', strip them\n",
        "from collections import OrderedDict\n",
        "new_state_dict = OrderedDict()\n",
        "for k, v in state_dict.items():\n",
        "    if k.startswith(\"embedding_net.\"):\n",
        "        new_state_dict[k.replace(\"embedding_net.\", \"\")] = v\n",
        "\n",
        "embedding_net.load_state_dict(new_state_dict)\n",
        "\n",
        "# Upsert songs\n",
        "points = []\n",
        "for idx, path in enumerate(tqdm(song_files, desc=\"Indexing songs\")):\n",
        "    try:\n",
        "        emb = embed_song(embedding_net, path, device=\"cpu\")  # use embedding_net here\n",
        "        emb = emb / np.linalg.norm(emb)\n",
        "        points.append(\n",
        "            rest.PointStruct(\n",
        "                id=idx,\n",
        "                vector=emb.tolist(),\n",
        "                payload={\"track\": os.path.basename(path)}\n",
        "            )\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Failed {path}: {e}\")\n",
        "\n",
        "# Bulk insert\n",
        "if points:\n",
        "    client.upsert(\n",
        "        collection_name=\"songs\",\n",
        "        points=points\n",
        "    )\n",
        "\n",
        "print(f\"âœ… Inserted {len(points)} songs into Qdrant\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHsPRendNjjS",
        "outputId": "07ad1f0d-9c1a-4ba6-c803-1faae8198dae"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2485338322.py:16: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
            "  client.recreate_collection(\n",
            "Indexing songs: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [02:01<00:00,  8.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Inserted 1000 songs into Qdrant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_path = song_files[512]  # pick any\n",
        "query_emb = embed_song(embedding_net, query_path)\n",
        "query_emb = query_emb / np.linalg.norm(query_emb)\n",
        "\n",
        "results = client.search(\n",
        "    collection_name=\"songs\",\n",
        "    query_vector=query_emb.tolist(),\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ”Ž Query:\", os.path.basename(query_path))\n",
        "for hit in results:\n",
        "    print(f\"Match: {hit.payload['track']} (score={hit.score:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5_B3sngNkse",
        "outputId": "e274d8f5-bce2-444d-dbef-5085fff8d3dd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”Ž Query: 011764.mp3\n",
            "Match: 011764.mp3 (score=1.000)\n",
            "Match: 010695.mp3 (score=0.576)\n",
            "Match: 001069.mp3 (score=0.529)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-553003862.py:5: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = client.search(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "# 1ï¸âƒ£ Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2ï¸âƒ£ Set the path to your file in Drive\n",
        "drive_file_path = \"/content/drive/MyDrive/wide_open.mp3\"  # adjust if needed\n",
        "local_path = \"/content/wide_open.mp3\"\n",
        "\n",
        "# 3ï¸âƒ£ Copy to Colab working directory\n",
        "shutil.copy(drive_file_path, local_path)\n",
        "\n",
        "# 4ï¸âƒ£ Check\n",
        "assert os.path.exists(local_path), \"File not found!\"\n",
        "print(f\"âœ… wide_open.mp3 copied to {local_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9y6nP6AsvD8",
        "outputId": "a371689e-9959-43dd-8875-33a8351487b3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… wide_open.mp3 copied to /content/wide_open.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchaudio\n",
        "import torch\n",
        "import numpy as np\n",
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import PointStruct\n",
        "\n",
        "song_path = \"/content/wide_open.mp3\"  # path to BeyoncÃ©'s Freedom\n",
        "collection_name = \"songs\"\n",
        "\n",
        "embedding_freedom = embed_song(embedding_net, song_path, device=\"cpu\")\n",
        "embedding_freedom = embedding_freedom / np.linalg.norm(embedding_freedom)  # normalize\n",
        "\n",
        "# ------------------------------\n",
        "# 3ï¸âƒ£ Connect to Qdrant\n",
        "# ------------------------------\n",
        "qdrant_client = client\n",
        "\n",
        "# Only create the collection if it doesn't exist\n",
        "if not qdrant_client.collection_exists(collection_name=collection_name):\n",
        "    qdrant_client.create_collection(\n",
        "        collection_name=collection_name,\n",
        "        vectors_config={\"size\": 128, \"distance\": \"Cosine\"}\n",
        "    )\n",
        "\n",
        "# ------------------------------\n",
        "# 4ï¸âƒ£ Upsert BeyoncÃ©'s Freedom\n",
        "# ------------------------------\n",
        "qdrant_client.upsert(\n",
        "    collection_name=collection_name,\n",
        "    points=[\n",
        "        PointStruct(\n",
        "            id=100001,  # unique ID\n",
        "            vector=embedding_freedom.tolist(),\n",
        "            payload={\"track\": \"CB - Wide Open\"}\n",
        "        )\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"âœ… Inserted 'CB - Wide Open' into Qdrant\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJp_4iSQiJm6",
        "outputId": "be0fa8e2-e690-4801-aa63-032478f08d37"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Inserted 'CB - Wide Open' into Qdrant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_path = \"/content/wide_open.mp3\"  # pick any\n",
        "query_emb = embed_song(embedding_net, query_path)\n",
        "query_emb = query_emb / np.linalg.norm(query_emb)\n",
        "\n",
        "results = client.search(\n",
        "    collection_name=\"songs\",\n",
        "    query_vector=query_emb.tolist(),\n",
        "    limit=3\n",
        ")\n",
        "\n",
        "print(\"\\nðŸ”Ž Query:\", os.path.basename(query_path))\n",
        "for hit in results:\n",
        "    print(f\"Match: {hit.payload['track']} (score={hit.score:.3f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4co1e2mtshd",
        "outputId": "83dad0d1-de94-453b-ef76-3d43c25489b1"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”Ž Query: wide_open.mp3\n",
            "Match: CB - Wide Open (score=1.000)\n",
            "Match: 004848.mp3 (score=0.642)\n",
            "Match: 012518.mp3 (score=0.629)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3266233890.py:5: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
            "  results = client.search(\n"
          ]
        }
      ]
    }
  ]
}